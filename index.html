<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: October 7, 2022 -->
<html lang="en-us">


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />

  <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />


  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

  <link rel="preload" as="style"
    href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap">
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap"
    media="print" onload="this.media='all'">


  <link rel="stylesheet" href="/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print"
    onload="this.media='all'">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css"
    integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg=="
    crossorigin="anonymous" media="print" onload="this.media='all'">


  <link rel="stylesheet" href="/css/wowchemy.6cd6d51f63e37d7b39117985b4040f0a.css" />

  <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print"
    onload="this.media='all'">
  <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'"
    disabled>

  <meta name="author" content="Nan Ma" />

  <meta name="description" content="A second-year master student in noisy correspondence learning and multimodal learning/>

<link rel=" alternate" hreflang="en-us" href="https://mamunan.github.io/" />
  <link rel="canonical" href="https://mamunan.github.io/" />

  <link rel="manifest" href="/manifest.webmanifest" />

  <link rel="icon" type="image/png" href="/authors/admin/Nan.jpg" />
  <link rel="apple-touch-icon" type="image/png" href="/authors/admin/Nan.jpg" />


  <meta name="theme-color" content="#3f51b5" />

  <meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@zxw" />
  <meta property="twitter:creator" content="@zxw" />
  <meta property="twitter:image" content="https://mamunan.github.io/authors/admin/Nan.jpg" />
  <meta property="og:site_name" content="Nan Ma (马楠)'s Homepage" />
  <meta property="og:url" content="https://mamunan.github.io/" />
  <meta property="og:title" content="Nan Ma (马楠)'s Homepage" />
<!--   <meta property="og:description" content="A second-year master student in noisy correspondence learning and multimodal learning" /> -->
  <meta property="og:image" content="https://mamunan.github.io/authors/admin/Nan.jpg" />
  <meta property="og:locale" content="en-us" />


  <meta property="og:updated_time" content="2030-06-01T13:00:00&#43;00:00" />

  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://mamunan.github.io/?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "url": "https://mamunan.github.io/"
}
</script>

  <script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Nan Ma (马楠)'s Homepage" />


  <style>
    code.custom-tag {
      display: inline-block;
      background-color: #224b8d; /* 深蓝色背景 */
      color: #FFFFFF;
      font-size: 0.5rem;
      padding: 0.1rem 0.2rem;
      border-radius: 0px;
      font-family: 'Courier New', Courier, monospace;
      font-weight: bold; /* 加粗字体 */
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
      vertical-align: middle;
    }
  </style>
  <title>Nan Ma (马楠)'s Homepage</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class="page-wrapper   ">

  <script src="/js/wowchemy-init.min.7532de8e15162845d694f17af8b46a99.js"></script>

  <aside class="search-modal" id="search">
    <div class="container">
      <section class="search-header">

        <div class="row no-gutters justify-content-between mb-3">
          <div class="col-6">
            <h1>Search</h1>
          </div>
          <div class="col-6 col-search-close">
            <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted"
                aria-hidden="true"></i></a>
          </div>
        </div>

        <div id="search-box">

          <input name="q" id="search-query" placeholder="Search..." autocapitalize="off" autocomplete="off"
            autocorrect="off" spellcheck="false" type="search" class="form-control" aria-label="Search...">

        </div>

      </section>
      <section class="section-search-results">

        <div id="search-hits">

        </div>

      </section>
    </div>
  </aside>

  <div class="page-header header--fixed">

    <header>
      <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
        <div class="container-xl">

          <div class="d-none d-lg-inline-flex">
            <a class="navbar-brand" href="/">Nan Ma</a>
          </div>

          <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-content"
            aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
            <span><i class="fas fa-bars"></i></span>
          </button>

          <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
            <a class="navbar-brand" href="/">Nan Ma</a>
          </div>

          <div class="navbar-collapse main-menu-item collapse justify-content-center" id="navbar-content">

            <ul class="navbar-nav d-md-inline-flex">

              <li class="nav-item">
                <a class="nav-link " href="/#about" data-target="#about"><span>Home</span></a>
              </li>

              <li class="nav-item">
                <a class="nav-link " href="/#publications" data-target="#publications"><span>Publications</span></a>
              </li>

              <li class="nav-item">
                <a class="nav-link " href="/#professional-services" data-target="#professional-services"><span>Professional Services</span></a>
              </li> 

              <li class="nav-item">
                <a class="nav-link " href="/#grants" data-target="#grants"><span>Grants & Projects</span></a>
              </li> 

              <li class="nav-item">
                <a class="nav-link " href="/#awards" data-target="#awards"><span>Awards & Honors</span></a>
              </li>

              <li class="nav-item">
                <a class="nav-link " href="/#talks" data-target="#talks"><span>Talks</span></a>
              </li>

              <li class="nav-item">
                <a class="nav-link " href="/#teaching" data-target="#teaching"><span>Teaching</span></a>
              </li>

<!--               <li class="nav-item">
                <a class="nav-link " href="/#experience" data-target="#experience"><span>Experience</span></a>
              </li> -->

            </ul>
          </div>

          <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

            <!-- <li class="nav-item">
              <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search"
                  aria-hidden="true"></i></a>
            </li> -->

            <li class="nav-item dropdown theme-dropdown">
              <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
                <i class="fas fa-moon" aria-hidden="true"></i>
              </a>
              <div class="dropdown-menu">
                <a href="#" class="dropdown-item js-set-theme-light">
                  <span>Light</span>
                </a>
                <a href="#" class="dropdown-item js-set-theme-dark">
                  <span>Dark</span>
                </a>
                <a href="#" class="dropdown-item js-set-theme-auto">
                  <span>Automatic</span>
                </a>
              </div>
            </li>

          </ul>

        </div>
      </nav>
    </header>


  </div>

  <div class="page-body">


    <span class="js-widget-page d-none"></span>

    <section id="about" class="home-section wg-about  ">
      <div class="home-section-bg ">

      </div>
      <div class="container">


        <div class="row">
          <div class="col-12 col-lg-4">
            <div id="profile">

              <!-- <img class="avatar avatar-circle" width="300" height="700" src="/authors/admin/Nan.jpg" alt="Nan Ma"> -->
              <div style="text-align: center; margin: 2rem 0;">
                <img class="avatar avatar-circle" 
                    src="/authors/admin/Nan.jpg" 
                    alt="Nan Ma"
                    style="width: 200px; height: 240px; object-fit: cover; border-radius: 50%; border: 3px solid #eee; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
              </div>

              <div class="portrait-title">

                <h3>
                  <a href="https://www.hqu.edu.cn/" target="_blank" rel="noopener">
                  </a>
                </h3>

              </div>

              <ul class="network-icon" aria-hidden="true">


                <li>
                  <a href="https://scholar.google.com.hk/citations?user=tRyS4M4AAAAJ&hl=zh-CN&oi=sra" target="_blank"
                    rel="noopener" aria-label="graduation-cap">
                    <!-- <i class="fas fa-graduation-cap big-icon"></i> -->
                    <img src="media\icons\brands\gs.png" style="width: 2rem; height: 2rem;" alt="Google Scholar" />
                  </a>
                </li>

                <li>
                  <a href="manan123@bjut.edu.cn" target="_blank"
                    rel="noopener" aria-label="graduation-cap">
                    <img src="media\icons\brands\email.webp" style="width: 2rem; height: 2rem;" alt="email" />
                  </a>
                </li>

      
              </ul>

            </div>
          </div>
          <div class="col-12 col-lg-8">

            <div class="profile-section" style="font-family: 'Helvetica Neue', Arial, sans-serif; color: #333;">
            <h1 style="font-size: 2.2rem; font-weight: 600; margin-bottom: 0.5rem;">
              Nan Ma <span style="font-family: 'STKaiti', '华文楷体', KaiTi, serif; font-weight: 500;">(马楠)</span>
            </h1>

              <h2 style="font-size: 1.5rem; font-weight: 600; margin-bottom: 0.8rem; color: #222; border-bottom: 1px solid #eee; padding-bottom: 0.5rem;">
                  Professor
              </h2>
              
              <div style="margin-left: 0.8rem;">
                  <p style="font-size: 1.05rem; margin-bottom: 0.5rem; line-height: 1.6;">
                     <strong>Vice Dean</strong>, School of Information Science and Technology, Beijing University of Technology 
                  </p>
          
                  <p style="font-size: 1.05rem; margin-bottom: 0.5rem; line-height: 1.6;">
                     <strong>Deputy Director</strong>, Engineering Research Center of Intelligence Perception and Autonomous Control, Ministry of Education
                  </p>
                  
                  <p style="font-size: 1.05rem; margin-bottom: 0.5rem; line-height: 1.6;">
                      <strong>Deputy Secretary General</strong>, Chinese Association for Artificial Intelligence
                  </p>
                 
              </div>
              
              <div style="background: #f8f9fa; padding: 0.8rem; border-radius: 4px; margin-top: 0.5rem;">
                  <p style="font-size: 1rem; margin-bottom: 0.4rem; color: #555;">
                      <i class="fas fa-building" style="width: 1.2rem; color: #777;"></i> 
                      <span style="margin-left: 0.3rem;">Room M827, The Science Building, Beijing University of Technology</span>
                  </p>
                
                  <p style="font-size: 1rem; margin-bottom: 0; color: #555;">
                      <i class="fas fa-envelope" style="width: 1.2rem; color: #777;"></i> 
                      <span style="margin-left: 0.3rem;">manan123@bjut.edu.cn</span>
                  </p>
              </div>
          
            
              <!-- Research Interests Section -->
              <div class="section-subheading" style="margin: 1.5rem 0 1rem 0; font-size: 1.25rem; font-weight: 600; color: #2c3e50;">
                Research Interests
              </div>
              
              <div style="margin-bottom: 1.5rem;">
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>Interactive Cognitive
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>Embodied Intelligence
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>Autonomous Driving
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>Intelligent Robot
                </p>
                <p style="font-size: 1.05rem; margin-bottom: 0.5rem; line-height: 1.6;">
                     I have published more than 90 papers in domestic and international academic journals and conferences, including IEEE TRO, TIP, TNNLS, TMM, PR, Science China Information Sciences, ACM MM and ICRA. 
                  </p>
              </div>
            </div>
          </div>


      </div>
    </section>


    <section id="info" class="home-section wg-info  ">
      <div class="home-section-bg ">

      </div>
      <div class="container">

        <section id="publications" class="home-section wg-pages">
          <div class="home-section-bg"></div>
          <div class="container">
            <div class="row">
              <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
                <h1 class="mb-0">Recent Work Highlights</h1>
              </div>
              
              <div class="col-12 col-lg-8" style="text-align: left;">
              <!-- Sci. China Inf. Sci. 2021 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q1</span>
                  <span style="background: linear-gradient(to right, #FB8C00, #FFA726); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 10px; font-size: 0.85em;">CCF A</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">Sci. China Inf. Sci.</code>
                  <a href="http://scis.scichina.com/en/2020/193201.pdf" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    Future vehicles: interactive wheeled robots
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    Science China Information Sciences, vol. 64, pp. 1-3, 2021. <br>
                    <span style="font-weight: 600;">Nan Ma</span>, <span>Deyi Li</span>, <span>Wen He</span>, <span>Yue Deng</span>, <span>Jiahong Li</span>, 
                    <span>Yue Gao</span>, <span>Hong Bao</span>, <span>Huan Zhang</span>, <span>Xinkai Xu</span>, 
                    <span>Yuansheng Liu</span>, <span>Zhixuan Wu</span>, <span>Li Chen</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="http://scis.scichina.com/en/2020/193201.pdf" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>
             
                
                <!-- Sci. China Inf. Sci. 2020 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q1</span>
                  <span style="background: linear-gradient(to right, #FB8C00, #FFA726); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 10px; font-size: 0.85em;">CCF A</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">Sci. China Inf. Sci.</code>
                  <a href="http://scis.scichina.com/en/2020/193201.pdf" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    Future Vehicle: Learnable Wheeled Robot
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    SCIENCE CHINA Information Sciences, vol. 63, no. 9, pp. 193201, 2020. <br>
                    <span>Deyi Li</span>, <span style="font-weight: 600;">Nan Ma*</span>, <span>Yue Gao</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="http://scis.scichina.com/en/2020/193201.pdf" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>
                
                <!-- 中国科学: 信息科学 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">SCIS</code>
                  <a href="https://dds.sciengine.com/cfs/files/pdfs/view/1674-7267/PkBLbTXpY8JaR3mXa-mark.pdf" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    自驾驶中的交互认知 [Interactive cognition in self-driving]
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    中国科学: 信息科学, vol. 48, no. 8, pp. 1083-1096, 2018. <br>
                    <span>马楠</span>, <span>高跃</span>, <span>李佳洪</span>, <span style="font-weight: 600;">李德毅*</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://dds.sciengine.com/cfs/files/pdfs/view/1674-7267/PkBLbTXpY8JaR3mXa-mark.pdf" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>
            
                <!-- IEEE Trans. Robot. 2025 -->
                  <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                    <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Robot Top</span>
                    <!-- <span style="background: linear-gradient(to right, #FB8C00, #FFA726); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 10px; font-size: 0.85em;">CCF A</span> -->
                    <code class="language-plaintext custom-tag" style="font-size: 0.6em;">T-RO</code>
                    <a href="#" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                      Autonomous Tomato Harvesting With Top-Down Fusion Network for Limited Data
                    </a>
                    <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                      IEEE Transactions on Robotics, vol. 41, pp. 3609-3628, 2025. <br>
                      <span>Xingxu Li</span>, <span>Yiheng Han</span>, <span style="font-weight: 600;">Nan Ma*</span>, <span>Yongjin Liu</span>, <span>Jia Pan</span>, <span>Shun Yang</span>, <span>Siyi Zheng</span>.
                    </div>
                    <div class="btn-links" style="margin-top: 0.5rem;">
                      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/abstract/document/10989552" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                        PDF
                      </a>
                    </div>
                  </div>

                <!-- TIP 2024 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q1</span>
                  <span style="background: linear-gradient(to right, #FB8C00, #FFA726); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 10px; font-size: 0.85em;">CCF A</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">TIP</code>
                  <a href="https://ieeexplore.ieee.org/abstract/document/10517892/" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    Multi-View Time-Series Hypergraph Neural Network for Action Recognition
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    IEEE Transactions on Image Processing, vol. 33, pp. 3301-3313, 2024. <br>
                    <span style="font-weight: 600;">Nan Ma</span>, <span>Zhixuan Wu</span>, <span>Yifan Feng, Cheng Wang, Yue Gao*</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/abstract/document/10517892/" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>

              <!-- Pattern Recognit. 2026 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q1</span>
                  <span style="background: linear-gradient(to right, #FFEB3B, #FFC107); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: #212529; margin-right: 10px; font-size: 0.85em;">CCF B</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">PR</code>
                  <a href="https://www.sciencedirect.com/science/article/pii/S003132032500785X" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    THTFormer: Topology-adaptive Hypergraph Transformer Network for Skeleton-based Action Recognition
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    Pattern Recognition, vol. 171, pp. 112125, 2026. <br>
                    <span style="font-weight: 600;">Nan Ma</span>, <span>Genbao Xu</span>, <span>Yiheng Han*</span>, <span>Beining Sun</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.sciencedirect.com/science/article/pii/S003132032500785X" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>

                <!-- ACM MM 2025 -->
                  <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                    <span style="background: linear-gradient(to right, #FB8C00, #FFA726); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 10px; font-size: 0.85em;">CCF A</span>
                    <code class="language-plaintext custom-tag" style="font-size: 0.6em;">ACM MM</code>
                    <a href="#" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                      Kinematic Enhanced Hypergraph Convolutional Network for Skeleton-based Human Action Recognition with LLM Training Guides
                    </a>
                    <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                      Proceedings of the 33th ACM International Conference on Multimedia (ACM MM 2025), Dublin, Ireland. <br>
                      <span style="font-weight: 600;">Nan Ma</span>, <span>Beining Sun</span>, <span>Yiheng Han*</span>, <span>Genbao Xu</span>.
                    </div>
                    <!-- <div class="btn-links" style="margin-top: 0.5rem;">
                      <a class="btn btn-outline-primary btn-page-header btn-sm" href="#" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                        PDF
                      </a>
                    </div> -->
                  </div>
        
                <!-- PR 2024 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q1</span>
                  <span style="background: linear-gradient(to right, #FFEB3B, #FFC107); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: #212529; margin-right: 10px; font-size: 0.85em;">CCF B</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">PR</code>
                  <a href="https://www.sciencedirect.com/science/article/pii/S003132032400178X/pdfft?md5=ccae496d0bf0d2685352fc7f2b04678b&pid=1-s2.0-S003132032400178X-main.pdf" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    Spatial-Temporal Hypergraph Based on Dual-Stage Attention Network for Multi-View Data Lightweight Action Recognition
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    Pattern Recognition, vol. 151, pp. 110427, 2024. <br>
                    <span>Zhixuan Wu</span>, <span style="font-weight: 600;">Nan Ma*</span>, <span>Cheng Wang, Cheng Xu, Genbao Xu, Mingxing Li</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.sciencedirect.com/science/article/pii/S003132032400178X/pdfft?md5=ccae496d0bf0d2685352fc7f2b04678b&pid=1-s2.0-S003132032400178X-main.pdf" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>

                <!-- IEEE Trans. Multimed. 2024 -->
                  <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                    <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q1</span>
                    <code class="language-plaintext custom-tag" style="font-size: 0.6em;">T-MM</code>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10494383" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                      Image-based Structured Vehicle Behavior Analysis Inspired by Interactive Cognition
                    </a>
                    <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                      IEEE Transactions on Multimedia, vol. 26, pp. 9121-9134, 2024. <br>
                      <span>Luntian Mou*</span>, <span>Haitao Xie</span>, <span>Shasha Mao</span>, <span>Dandan Yan</span>, <span style="font-weight: 600;">Nan Ma*</span>, <span>Baocai Yin</span>, <span>Wen Gao</span>.
                    </div>
                    <div class="btn-links" style="margin-top: 0.5rem;">
                      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/abstract/document/10494383" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                        PDF
                      </a>
                    </div>
                  </div>

                 <!-- ICRA 2024 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Robot Top</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">ICRA</code>
                  <a href="https://ieeexplore.ieee.org/document/10610549" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    FF-LOGO: Cross-Modality Point Cloud Registration with Feature Filtering and Local to Global Optimization
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 744-750, 2024. <br>
                    <span style="font-weight: 600;">Nan Ma</span>, <span>Mohan Wang, Yihan Han*, and Yongjin Liu</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/document/10610549" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>

                <!-- ICRA 2024 -->
                  <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Robot Top</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">ICRA</code>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10610454" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                      AHPPEBot: Autonomous Robot for Tomato Harvesting based on Phenotyping and Pose Estimation
                    </a>
                    <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                      2024 IEEE International Conference on Robotics and Automation (ICRA), pp. 18150-18156, 2024. <br>
                      <span>Xingxu Li</span>, <span style="font-weight: 600;">Nan Ma*</span>, <span>Yiheng Han</span>, <span>Shun Yang</span>, <span>Siyi Zheng</span>.
                    </div>
                    <div class="btn-links" style="margin-top: 0.5rem;">
                      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/abstract/document/10610454" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                        PDF
                      </a>
                    </div>
                  </div>

                <!-- Expert Syst. Appl. 2023 -->
                  <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                    <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q2 Top</span>
                    <code class="language-plaintext custom-tag" style="font-size: 0.6em;">ESWA</code>
                    <a href="https://www.researchgate.net/profile/Luntian-Mou/publication/373089388_Multimodal_driver_distraction_detection_using_dual-channel_network_of_CNN_and_Transformer/links/64d77cd325837316ee093363/Multimodal-driver-distraction-detection-using-dual-channel-network-of-CNN-and-Transformer.pdf" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                      Multimodal driver distraction detection using dual-channel network of CNN and Transformer
                    </a>
                    <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                      Expert Systems with Applications, vol. 234, pp. 121066, 2023. <br>
                      <span style="font-weight: 600;">Luntian Mou*</span>, <span>Jiali Chang</span>, <span>Chao Zhou</span>, <span>Yiyuan Zhao</span>, <span style="font-weight: 600;">Nan Ma*</span>, <span>Baocai Yin</span>, <span>Ramesh Jain</span>, <span>Wen Gao</span>.
                    </div>
                    <div class="btn-links" style="margin-top: 0.5rem;">
                      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.researchgate.net/profile/Luntian-Mou/publication/373089388_Multimodal_driver_distraction_detection_using_dual-channel_network_of_CNN_and_Transformer/links/64d77cd325837316ee093363/Multimodal-driver-distraction-detection-using-dual-channel-network-of-CNN-and-Transformer.pdf" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                        PDF
                      </a>
                    </div>
                  </div>

                <!-- IEEE Trans. Image Process. 2023 -->
                  <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                    <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q1</span>
                    <span style="background: linear-gradient(to right, #FB8C00, #FFA726); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 10px; font-size: 0.85em;">CCF A</span>
                    <code class="language-plaintext custom-tag" style="font-size: 0.6em;">T-IP</code>
                    <a href="#" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                      Exploring High-order Spatio-temporal Correlations from Skeleton for Person Re-identification
                    </a>
                    <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                      IEEE Transactions on Image Processing, vol. 32, pp. 949-969, 2023. <br>
                      <span>Jiaxuan Lu</span>, <span>Hai Wan</span>, <span>Peiyan Li</span>, <span>Xibin Zhao</span>, <span style="font-weight: 600;">Nan Ma*</span>, <span>Yue Gao*</span>.
                    </div>
                    <div class="btn-links" style="margin-top: 0.5rem;">
                      <a class="btn btn-outline-primary btn-page-header btn-sm" href="#" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                        PDF
                      </a>
                    </div>
                  </div>

        
                <!-- Tsinghua ST 2022 -->
                <div class="view-list view-list-item" style="margin-bottom: 1.5rem;">
                  <span style="background: linear-gradient(to right, #1976D2, #2196F3); padding: 2px 8px; border-radius: 4px; font-weight: bold; color: white; margin-right: 6px; font-size: 0.85em;">Q2</span>
                  <code class="language-plaintext custom-tag" style="font-size: 0.6em;">TSINGHUA SCI TECHNOL</code>
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802874" target="_blank" rel="noopener" style="text-decoration: none; color: #212529;">
                    A Survey of Human Action Recognition and Posture Prediction
                  </a>
                  <div class="article-metadata" style="margin-top: 0.5rem; font-size: 0.9em; color: #6c757d;">
                    Tsinghua Science and Technology, vol. 27, no. 6, pp. 973-1001, 2022. <br>
                    <span style="font-weight: 600;">Nan Ma*</span>, <span>Zhixuan Wu</span>, <span>Yiu-ming Cheung, Yuchen Guo, Yue Gao, Jiahong Li, Beijyan Jiang</span>.
                  </div>
                  <div class="btn-links" style="margin-top: 0.5rem;">
                    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802874" target="_blank" rel="noopener" style="font-size: 0.8em; padding: 0.15rem 0.5rem;">
                      PDF
                    </a>
                  </div>
                </div>

          <div class="section-subheading" style="margin: 1.5rem 0 1rem 0; font-size: 1.25rem; font-weight: 600; color: #2c3e50;">
                Main Publications
              </div>
          
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [1] Nan Ma, Deyi Li*, Wen He, Yue Deng, Jiahong Li, Yue Gao, Hong Bao, Huan Zhang, Xinkai Xu, Yuansheng Liu, Zhixuan Wu, Li Chen. Future vehicles: interactive wheeled robots[J]. Science China-Information Sciences, 2021, 64 (5): 56101:1–156101:3.
        </p>
        <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [2] Deyi Li, Nan Ma*, Yue Gao. Future Vehicle: Learnable Wheeled Robot[J]. Science China-Information Sciences, 2020, 63 (9):193201.
        </p>
        <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [3] 马楠,高跃,李佳洪,李德毅*.自驾驶中的交互认知[J]. 中国科学：信息科学, 2018, 48(8): 1083–1096.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [4] Xingxu Li, Yiheng Han, Nan Ma*, Yongjin Liu, Jia Pan, Shun Yang, Siyi Zheng. Autonomous Tomato Harvesting With Top–Down Fusion Network for Limited Data[J]. IEEE Transactions on Robotics, 2025, 41: 3609-3628.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [5] Nan Ma, Zhixuan Wu, Yifan Feng, Cheng Wang and Yue Gao*, Multi-View Time-Series Hypergraph Neural Network for Action Recognition[J]. IEEE Transactions on Image Processing, 2024, 33: 3301-3313.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [6] Zhixuan Wu, Nan Ma*, Cheng Wang, Cheng Xu, Genbao Xu, Mingxing Li. Spatial-temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition[J]. Pattern Recognition, 2024: 110427.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [7] Luntian Mou*, Haitao Xie, Shasha Mao, Dandan Yan, Nan Ma*, Baocai Yin, Wen Gao. Image-based Structured Vehicle Behavior Analysis Inspired by Interactive Cognition[J]. IEEE Transactions on Multimedia, 2024, 26, 9121–9134.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [8] Jiaxuan Lu, Hai Wan, Peiyan Li, Xibin Zhao,Nan Ma*, Yue Gao*. Exploring High-order Spatio-temporal Correlations from Skeleton for Person Re-identification[J]. IEEE Transactions on Image Processing, 2023, 32:949-969.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [9] Heyuan Shi, Yubo Zhang, Zizhao Zhang, Nan Ma*, Xibin Zhao, Yue Gao*, Jiaguang Sun. Hypergraph-Induced Convolutional Networks for Visual Classification[J]. IEEE Transactions on Neural Networks and Learning Systems, 2019, 30(10): 2963-2972.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [10] Nan Ma*, Zhixuan Wu, Yue Gao, Yuchen Guo, Jiahong Li. A Survey of Human Action Recognition and Posture Prediction[J]. Tsinghua Science and Technology, 2022, 27(6), 973-1001.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [11] Luntian Mou*, Jiali Chang, Chao Zhou, Yiyuan Zhao, Nan Ma*, Baocai Yin, Ramesh Jain, Wen Gao. Multimodal driver distraction detection using dual-channel network of CNN and Transformer[J]. Expert Systems with Applications, 2023, 234: 121066.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [12] Li Chen, Nan Ma*, Patrick Wang, Guilin Pang, Xiaojun Shi. Survey of pedestrian action recognition techniques for autonomous driving[J]. Tsinghua Science and Technology, 2020, 25(4): 458-470.
          </p>
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [13] Zhixuan Wu, Nan Ma*, Yue Gao, Jiahong Li, Xinkai Xu, Yongqiang Yao, Li Chen. Attention Mechanism Based on Improved Spatial-Temporal Convolutional Neural Networks for Traffic Police Gesture Recognition[J]. International Journal of Pattern Recognition and Artificial Intelligence, 2022, 36(8), 2256001:1-2256001:19.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [14] Yongqiang Yao, Nan Ma*, Cheng Wang, Zhixuan Wu, Cheng Xu, Jin Zhang. Research and implementation of variable-domain fuzzy PID intelligent control method based on Q-Learning for self-driving in complex scenarios[J]. Mathematical Biosciences and Engineering, 2023, 20(3): 6016-6029.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [15] Nan Ma, Hamido Fujita, Yun Zhai, Shupeng Wang. Ensembles of Fuzzy Cognitive Map Classifiers Based on Quantum Computation[J]. Acta Polytechnica Hungarica, 2015, 12(4) :7-20.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [16] Nan Ma, Sicheng Zhao, Zhen Sun, Xiuping Wu, Yun Zhai. An improved ridge regression algorithm and its application in predicting TV ratings[J]. Multimedia Tools and Applications, 2019, 78 (1): 525-535.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [17] Nan Ma, Patrick Wang, Qin He, Wenjia Li, Ying Zheng. Prediction of Television Audience Rating Based on Fuzzy Cognitive Maps with Forward Stepwise Regression[J]. International Journal of Pattern Recognition and Artificial Intelligence, 2017, 31 (1): 1-13.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [18] Nan Ma, Mohan Wang, Yihan Han*, and Yongjin Liu. FF−LOGO: Cross−Modality Point Cloud Registration with Feature Filtering and Local to Global Optimization[C]//2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024: 744-750..
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [19] Xingxu Li, Nan Ma*, Yiheng Han, Shun Yang, and Siyi Zheng. AHPPEBot: Autonomous Robot for Tomato Harvesting based on Phenotyping and Pose Estimation[C]//2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024: 18150-18156.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [20] Nan Ma, Beining Sun, Yiheng Han* and Genbao Xu. Kinematic Enhanced Hypergraph Convolutional Network for Skeleton-based Human Action Recognition with LLM Training Guides[C].In Proceedings of the 33th ACM International Conference on Multimedia (Dublin,Ireland) (ACM MM 2025) (已录用)
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [21] Nan Ma, Genbao Xu, Yiheng Han*, Beining Sun. SA-P2T: Sparse Attention-based Pyramid Pooling Transformer Network for Object Detection[C]//2024 IEEE 24th International Conference on Software Quality, Reliability, and Security Companion (QRS-C). IEEE, 2024: 946-951. Best Paper
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [22] Nan Ma, Tiancong Han, Qin Xia, Yiheng Han*. Road Information Recognition and Decision Making Based on YOLO Algorithm[C]//2024 3rd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR). IEEE, 2024: 197-202. Best paper
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [23] Nan Ma, Jiahui Wang, Kongjian Qin , Yiheng Han*. A Real-Time Vehicle Detection and Tracking System Based on an Improved YOLOv5 with Lightweight Convolutions and Multi-Scale Fusion Combined with BYTETrack[C]//2024 3rd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR). IEEE, 2024: 203-209. Best paper
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [24] Zhixuan Wu, Nan Ma*, Tao Zhi and Genbao Xu. Spatial-Temporal Hypergraph Neural Network based on Attention Mechanism for Multi-view Data Action Recognition[C]//2023 10th International Conference on Dependable Systems and Their Applications (DSA). IEEE, 2023: 487-493. Best Paper
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [25] Xiaokang Chen, Nan Ma*, Mohan Wang. Yolov5-pothole:an improved road pothole perception method based on yolov5-seg[C]//The 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR 2023), 2023. Best paper
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [26] Nan Ma*, Beining Sun, Zhixuan Wu, Tao Zhi, Genbao Xu, Mohan Wang. A Survey of Human Action Recognition Based on Graph Convolutional Networks[C]//The 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR 2023), 2023. Best paper
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [27] Nan Ma, Shangyuan Li, Yiheng Han*, Mohan Wang. PreBEV: Leveraging Predictive Flow for Enhanced Bird's-Eye View 3D Dynamic Object Detection[C]//2024 IEEE 24th International Conference on Software Quality, Reliability, and Security Companion (QRS-C). IEEE, 2024: 1062-1066.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [28] Nan Ma, Weien Suo, Qin Xia, Yiheng Han*. Construction and Performance Evaluation of a Comprehensive Multi-Scenario Road Vehicle and Pedestrian Detection Dataset[C]//2024 3rd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR). IEEE, 2024: 210-215.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [29] Nan Ma, Zhijie Liu, Yiheng Han*, Jichang Ma. A review of cross-modal 3D point cloud semantic segmentation methods based on deep learning[C]//2024 2nd International Conference on Computer, Vision and Intelligent Technology (ICCVIT). IEEE, 2024: 1-6.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [30] Shangyuan Li, Nan Ma*, Zhixuan Wu, Qiang Lin. License Plate Detection and Recognition Based on Light-Yolov7[C]//Chinese Intelligent Automation Conference. Singapore: Springer Nature Singapore, 2023: 83-91.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [31] Feifan He, Nan Ma*, Xingxu Li, Zhijie Liu. A Review of Multi-agent Collaborative Control[C]//The 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR 2023), 2023: 506-510.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [32] Zecheng Yang, Nan Ma*, Yongqiang Yao. A Survey on Cooperative Control of Multi-agent Systems[C]//International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR 2023), 2023: 511-515.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [33] Nan Ma*, Shangyuan Li, Chuansheng Xiao, Mohan Wang, Beining Sun, and Mengye Zhang. A review of SAM-based visual semantic segmentation[C]//2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR). IEEE, 2023: 496-500.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [34] Nan Ma*, Mengye Zhang, Mohan Wang, Genbao Xu, Chuansheng Xiao, Shangyuan Li. A Review of Graph Convolutional Networks for Skeleton-based Human Action Recognition[C]//The Nineteenth International Conference on Computational Intelligence and Security (CIS'2023), 2023.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [35] Chuansheng Xiao, Nan Ma*, Kongjian Qin, Genbao Xu, Mohan Wang. BIR−AHC: Balanced Iterative Reducing and Agglomerative Hierarchical Clustering for Stair Detection.[C]//2023 10th International Conference on Dependable Systems and Their Applications (DSA). IEEE, 2023: 623-627.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [36] Nan Ma*, Chuansheng Xiao, Mohan Wang, Genbao Xu. A review of point cloud and image cross-modal fusion for self-driving[C]//2022 18th International Conference on Computational Intelligence and Security (CIS). IEEE, 2022: 456-460.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [37] Nan Ma, Li Chen, Jiancheng Hu, Qiuna Shang, Jiahong Li, Guoping Zhang. Pedestrian Detection Based on HOG Features and SVM Realizes Vehicle-Human Environment Interaction[C]// The 15th International Conference on Computational Intelligence and Security (CIS2019), Macao, China, 2019.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [38] Zhixuan Wu, Nan Ma*, Yongqiang Yao, Guoping Zhang. Survey of Action Recognition Based on Attention Mechanism[C]//Proceedings of 2021 Chinese Intelligent Automation Conference. Springer, Singapore, 2022, pp. 555-563.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [39] Li Chen, Nan Ma*, Guoping Zhang. Bi-GRU-Attention Enhanced Unsupervised Network for Skeleton-Based Action Recognition [C] //2021 International Conference on Autonomous Unmanned Systems (ICAUS 2021), 2021, pp. 1090-1098.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [40] Yongqiang Yao, Nan Ma*, Jiahong Li, Zhixuan Wu, Guoping Zhang. Emergency Obstacle Avoidance based on Gradient Descent Distance for Self-driving Vehicles [C]//2021 International Conference on Autonomous Unmanned Systems (ICAUS 2021). Springer, Singapore, 2021: 2980-2989.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [41] Zongli Jiang, Jieru Liang, Nan Ma*, An Graph Neural Network and Feature Interaction Based Fraud Detection[C]//2021 17th International Conference on Computational Intelligence and Security (CIS 2021), 2021: 464-468.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [42] Yongqiang Yao, Nan Ma*, Jiahong Li, Zhixuan Wu, Guoping Zhang. Research on Control Method of Self-driving Vehicle Based on Adaptive Fuzzy PID[C]//2021 17th International Conference on Computational Intelligence and Security (CIS 2021), 2021: 212-216.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [43] Jiahong Li, Nan Ma*. Design of Vehicle Cooperative localization System Based on Cooperative Communication Switching Strategy [C]//2021 17th International Conference on Computational Intelligence and Security (CIS 2021), 2021: 237-241.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [44] Guoping Zhang, Nan Ma*, Jiahong Li, Beiyan Jiang, Zhixuan Wu. Gesture Recognition Algorithm Based on Lightweight 3DCNN Network[C]//2021 17th International Conference on Computational Intelligence and Security (CIS 2021), 2021: 217-221.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [45] Jiahong Li, Nan Ma, Fang Deng. Distributed Noise Covariance Matrices Estimation in Sensor Networks[D]. in IEEE 59th Conference on Decision and Control (CDC), Jeju Island, Republic of Korea, Dec. 2020, pp. 1-6.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [46] Zhixuan Wu, Nan Ma*, Yiu-ming Cheung, Jiahong Li, Qin He, Yongqiang Yao, Guoping Zhang. Improved Spatio-Temporal Convolutional Neural Networks for Traffic Police Gestures Recognition[C]//International Conference on Computational Intelligence and Security(CIS2020), 2020, pp. 109-115.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [47] Jiahong Li, Nan Ma, Xiangmin Han. Multi-agent Robust Time Differential Reinforcement Learning over communicated networks[C]//2018 37th Chinese Control Conference (CCC). IEEE, 2018: 7221-7225.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [48] Li Chen, Nan Ma*, Pengfei Wang, et al. Survey of Pedestrian Action Recognition in Autonomous Driving[C]//2018 Third International Conference on Cognitive Systems and Information Processing (ICCSIP 2018), 2018.
          </p><p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [51] 陈丽, 马楠*, 逄桂林, 高跃, 李佳洪, 张国平, 吴祉璇, 姚永强. 多视角数据融合的特征平衡YOLOv3行人检测研究[J].智能系统学报, 2021, 16(1): 9.
          <p style="font-size: 0.7rem; margin-bottom: 0.5rem; line-height: 1.6; text-align: justify; text-justify: inter-word; hyphens: auto;">
          [52] 张国平, 马楠, 贯怀光, 吴祉璇. 深度学习方法在二维人体姿态估计的研究进展[J].计算机科学, 2022, 49(12):219-228.
          </p>
                
         </div>
        </div>
      </div>
                
        </section>

    <section id="info" class="home-section wg-info  ">
      <div class="home-section-bg ">

      </div>
      <div class="container">

        <section id="professional-services" class="home-section wg-pages">
          <div class="home-section-bg"></div>
          <div class="container">
            <div class="row">
              <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
                <h1 class="mb-0">Professional Services</h1>
              </div>

              <div class="col-12 col-lg-8" style="text-align: left;">
                  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Deputy Secretary General</span>, Chinese Association for Artificial Intelligence
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Deputy Director and Secretary-General of the Education Working Committee</span>, Chinese Association for Artificial Intelligence (CAAI)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Distinguished Member</span>, China Society of Image and Graphics (CSIG)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Standing Council Member and Chair of the Women in Science and Technology Committee</span>, Beijing Society of Image and Graphics
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Editorial Board Member</span>, Intelligent Computing, Journal of Intelligent Systems (智能系统学报)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Associate Editors</span>, International Journal of Pattern Recognition and Artificial Intelligence (IJPRAI)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">enior Member</span>, Institute of Electrical and Electronics Engineers (IEEE), IEEE Computational Intelligence Society (CIS)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">General-Chair</span>, International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics; IEEE International Symposium on Autonomous Vehicle Software
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Session Chair</span>, International Conference on Brain Informatics (BI 2019); International Conference on Cognitive System and Information Processing (ICCSIP 2018)
                </p>
              </div>

    </div>
        </div>
      </div>
                
        </section>
          
    <section id="grants" class="home-section wg-pages">
          <div class="home-section-bg"></div>
          <div class="container">
            <div class="row">
              <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
                <h1 class="mb-0">Research Grants and Projects</h1>
              </div>

          <div class="col-12 col-lg-8" style="text-align: left;">
                  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">National Key R&D Program of China</span>, "National Quality Infrastructure System" Key Special Project: Multi-Dimensional Data Calibration Key Technologies and Standards for Quality Trustworthiness (2023–2027)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Beijing Natural Science Foundation–Shunyi Innovation Joint Fund</span>, User Behavior Analysis, Modeling, and Evaluation Based on Multi-Modal Data in Intelligent Cockpit Interaction (2024–2026)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Beijing Science and Technology Plan Project</span>, Intelligent Manufacturing and Robotics Innovation: Humanoid Robot Perception in Dynamic Indoor/Outdoor Environments and 3D Navigation (2022–2023)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">National Natural Science Foundation of China (NSFC) General Program</span>, Theory and Technology of Cross-Modal Visual Information Acquisition and Processing for Autonomous Vehicles (2024–2027)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">National Natural Science Foundation of China (NSFC) General Program</span>, Key Technologies for Multi-View Video Information Acquisition and Localization in Autonomous Vehicles (2019–2022)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">National Natural Science Foundation of China (NSFC) Key Program</span>, Theory and Methods of Coded Imaging for Front-End Fusion (2020–2024)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Qiyuan Laboratory Innovation Fund (Exploratory Research)</span>, Key Technologies for Interactive Cognition and Collaboration in Intelligent Robotics (2023–2024)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Beijing Natural Science Foundation General Program</span>, Behavior Recognition in Complex Scenarios for Autonomous Driving (2022–2024)
                </p>
                <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
                  <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span><span style="font-weight: 600;">Beijing Natural Science Foundation General Program</span>, Multi-View Object Recognition for Autonomous Vehicles (2018–2020), <span style="font-weight: 600;">Rated "Excellent" upon completion</span>
                </p>
</div>
        </div>
      </div>              
        </section>
               
    <section id="awards" class="home-section wg-pages">
      <div class="home-section-bg"></div>
      <div class="container">
        <div class="row">
          <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class="mb-0">Honors and Awards</h1>
          </div>

      <div class="col-12 col-lg-8" style="text-align: left;">
        <div class="honors-list">
          <!-- National/Professional Awards -->
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">First Prize</span>, China Science and Technology Progress Award (CSIG, 2022) - 
            <em>Key Technologies and Applications of Visual Understanding and Interactive Cognition for Mobile Robots in Complex Scenarios</em> (First Rank)
          </p>
          
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Second Prize</span>, China Electronics Society Science and Technology Award - Technology Invention Category (2020) - 
            <em>Intelligent Interaction Technology and Applications for Autonomous Driving</em> (First Rank)
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">First Prize</span>, China Electronics Society Science and Technology Award - Natural Science Category (2022) - 
            <em>Complex Correlation Computing for Visual Information</em> (Third Rank)
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Outstanding Women in Science and Technology Award</span>, Beijing Society of Image and Graphics (2022)
          </p>

          <!-- Best Paper Awards -->
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Best Paper Award</span>, IEEE International Symposium on Autonomous Vehicle Software (AVS 2024)
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Best Paper Award</span>, IEEE International Symposium on Autonomous Vehicle Software (AVS 2023)
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Best Paper Award</span>, 3rd International Conference on AI, HCI and Robotics (AIHCIR 2024)
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Best Paper Award</span>, 2nd International Conference on AI, HCI and Robotics (AIHCIR 2023)
          </p>

          <!-- Conference Organization Awards -->
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Best Workshop Organization Award</span>, 2022 International Conference on VR, HCI and AI (VRHCIAI) - 
            <em>Intelligent Interaction Technology Workshop</em>
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Best Workshop Organization Award</span>, 2nd International Conference on Image, Vision and Intelligent Systems (ICIVIS 2022) - 
            <em>IntelliSense and Cross-modal Recognition Workshop</em>
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Outstanding Contribution Award</span>, IEEE International Symposium on Autonomous Vehicle Software (AVS 2023)
          </p>

          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span style="font-weight: 600;">Excellence in Service as Chair</span>, 2nd International Conference on AI, HCI and Robotics (AIHCIR 2023)
          </p>
         <div class="teaching-achievements" style="text-align: left;">
  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
    <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
    <span style="font-weight: 600;">Lead Instructor</span>, MOOC <em>"Intelligent Interaction Technology"</em> on China University MOOC platform, certified as <span style="font-weight: 600;">National First-Class Online Course</span>
  </p>
  
  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
    <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
    <span style="font-weight: 600;">Chief Editor</span>, textbook <em>"Intelligent Interaction Technologies and Applications"</em>: Selected for <span style="font-weight: 600;">National Key Publications Planning Project (13th Five-Year Plan)</span> and awarded <span style="font-weight: 600;">Beijing Higher Education "High-Quality Textbook & Courseware"</span> (2021)
  </p>

  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
    <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
    <span style="font-weight: 600;">Chief Editor</span>, <em>"Intelligent Interaction Technologies and Applications (2nd ed.)"</em>: Selected for <span style="font-weight: 600;">MOE's Strategic Emerging Fields "14th Five-Year Plan" Higher Education Textbook Plan</span>
  </p>

  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
    <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
    <span style="font-weight: 600;">Second Prize</span>, <em>6th National Outstanding Achievement Award in Educational Science Research</em> (2022) for <em>"Education in the Intelligent Age"</em> (Second Contributor)
  </p>

  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
    <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
    <span style="font-weight: 600;">Second Prize</span>, <em>Beijing Higher Education Teaching Achievement Award</em> (2022) for <em>"Exploration and Practice of New Engineering Talent Cultivation Model for Robotics Industry"</em> (Second Contributor)
  </p>

  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
    <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
    <span style="font-weight: 600;">Second Prize</span>, <em>Beijing Higher Education Teaching Achievement Award</em> (2018) for <em>"Cultivating Innovative Talent in Intelligent Robotics via Science-Mission-Driven Approaches"</em> (Third Contributor)
  </p>

  <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
    <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
    <span style="font-weight: 600;">Second Prize</span>, <em>University-Level Teaching Achievement Award</em> (2020) for <em>"Three-Dimensional Curriculum Development for New Engineering Education"</em> (Lead Contributor)
  </p>

        </div>
      </div>
    </div>
  </div>
</section>

<section id="talks" class="home-section wg-pages">
      <div class="home-section-bg"></div>
      <div class="container">
        <div class="row">
          <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class="mb-0">Talks</h1>
          </div>

          <div class="col-12 col-lg-8" style="text-align: left;">
            <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span>Research on Interactive Cognition Technology in Coordination between “Human-Vehicle-Road" for Unmanned Vehicle </span>
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span>Research on Interactive Cognition in Coordination Between Human-vehicle-road for Unmanned Vehicle </span>
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span>Embodied Interactive intelligence of Unmanned-driving </span>
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            <span>Embodied Interactive Intelligence Towards Autonomous Driving </span>
          </p>
      </div>
      </div>
    </div>
  </div>
</section>

<section id="teaching" class="home-section wg-pages">
  <div class="home-section-bg"></div>
  <div class="container">
    <div class="row">
      <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
        <h1 class="mb-0">Teaching</h1>
      </div>
      
      <div class="col-12 col-lg-8" style="text-align: left;">
        <div class="teaching-list">
          <h3 style="font-size: 1.1rem; margin-bottom: 0.8rem;">Undergraduate Courses</h3>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            Principles of Database Systems (Bilingual Instruction)
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            Fundamental Database Practices
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            Intelligent Human-Robot Interaction
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            Machine Learning
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            Training for University Student Robotics Competitions (Competition-based Course)
          </p>
          
          <h3 style="font-size: 1.1rem; margin: 1.2rem 0 0.8rem 0;">Graduate Courses</h3>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            Machine Intelligence Interaction
          </p>
          <p style="margin: 0 0 0.6rem 0; padding-left: 1.5rem; position: relative; font-size: 0.9rem; line-height: 1.6;">
            <span style="position: absolute; left: 0.5rem; color: #7f8c8d;">•</span>
            Advanced Database Systems
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


    <!--  <section id="research" class="home-section wg-portfolio  "  >-->
    <!--   <div class="home-section-bg " >-->
    <!--     -->
    <!--   </div>-->
    <!--    <div class="container">-->

    <!--      <div class="row  ">-->
    <!--        -->
    <!--          <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">-->
    <!--            <h1 class="mb-0">Research</h1>-->
    <!--            -->
    <!--          </div>-->

    <!--<div class="col-12 col-lg-8">-->

    <!--    <span class="d-none default-project-filter">*</span>-->
    <!--    -->
    <!--    <div class="project-toolbar">-->
    <!--      <div class="project-filters">-->
    <!--        <div class="btn-toolbar ">-->
    <!--          <div class="btn-group flex-wrap">-->
    <!--              <a href="#" data-filter="*" class="btn btn-primary btn-lg active">All</a>-->
    <!--              <a href="#" data-filter=".js-id-optimal-control" class="btn btn-primary btn-lg">Optimal Control</a>-->
    <!--              <a href="#" data-filter=".js-id-reinforcement-learning" class="btn btn-primary btn-lg">Reinforcement Learning</a>-->
    <!--              <a href="#" data-filter=".js-id-legged-robot" class="btn btn-primary btn-lg">Legged Robot</a>-->
    <!--              <a href="#" data-filter=".js-id-demo" class="btn btn-primary btn-lg">Other</a>-->
    <!--          </div>-->
    <!--        </div>-->
    <!--      </div>-->
    <!--    </div>-->

    <!--  <div class="isotope projects-container row js-layout-row ">-->

    <!--          <div class="col-12 isotope-item js-id-optimal-control js-id-quadruped-robot js-id-reinforcement-learning js-id-bipedal-robot">-->
    <!--        -->
    <!--<div class="col-lg-12 mb-5 view-showcase">-->
    <!--  <div class="row align-items-center">-->
    <!--    <div class="col-12 col-md-6">-->
    <!--      <div class="section-subheading article-title mb-0 mt-0"><a href="/research/quadruped_two_leg_walking/" >Quadruped robot walking like lizard with two point feet</a></div>-->

    <!--      <div class="article-style">-->
    <!--        A research topic focus on using optimization approaches to give quadruped robot two point feet walking ability.-->
    <!--      </div>-->

    <!--      <div class="btn-links">-->
    <!--        -->
    <!--  <a class="btn btn-outline-primary btn-page-header" href="https://www.zhihu.com/people/yuexiaozhu" target="_blank" rel="noopener">-->
    <!--    <i class="fab fa-zhihu mr-1"></i>Follow</a>-->

    <!--      </div>-->

    <!--    </div>-->
    <!--    <div class="col-12 col-md-6 order-first ">-->
    <!--        <a href="/research/quadruped_two_leg_walking/" >-->
    <!--          <img src="/research/quadruped_two_leg_walking/featured_hu662ea52dbf45263bba1eb5c07304d0d9_743643_540x0_resize_q75_h2_lanczos_3.webp" height="248" width="540"-->
    <!--              alt="Quadruped robot walking like lizard with two point feet" loading="lazy">-->
    <!--        </a>-->
    <!--      -->
    <!--    </div>-->
    <!--  </div>-->
    <!--</div>-->

    <!--      </div>-->
    <!--    -->
    <!--          <div class="col-12 isotope-item js-id-optimal-control js-id-quadruped-robot js-id-reinforcement-learning js-id-bipedal-robot">-->


    <!--<div class="col-lg-12 mb-5 view-showcase">-->
    <!--  <div class="row align-items-center">-->
    <!--    <div class="col-12 col-md-6">-->
    <!--      <div class="section-subheading article-title mb-0 mt-0"><a href="/research/offline_quadruped_jumping/" >Quadruped jumping with optimal control</a></div>-->
    <!--      -->
    <!--      <div class="article-style">-->
    <!--        A research topic focus on using optimization approaches to give legged robot jumping ability.-->
    <!--      </div>-->

    <!--      <div class="btn-links">-->
    <!--<a class="btn btn-outline-primary btn-page-header" href="https://www.youtube.com/playlist?list=PLKHWv6i0gB-9KobcKvvrprYk5VArDbhFk" target="_blank" rel="noopener">-->
    <!--  Video-->
    <!--</a>-->

    <!--  <a class="btn btn-outline-primary btn-page-header" href="https://www.zhihu.com/people/yuexiaozhu" target="_blank" rel="noopener">-->
    <!--    <i class="fab fa-zhihu mr-1"></i>Follow</a>-->

    <!--      </div>-->

    <!--    </div>-->
    <!--    <div class="col-12 col-md-6 order-first ">-->
    <!--      -->
    <!--        <a href="/research/offline_quadruped_jumping/" >-->
    <!--          <img src="/research/offline_quadruped_jumping/featured_hu031f41de6e98c5f0a0a9564fdd879ecb_1098367_540x0_resize_q75_h2_lanczos_3.webp" height="271" width="540"-->
    <!--              alt="Quadruped jumping with optimal control" loading="lazy">-->
    <!--        </a>-->
    <!--      -->
    <!--    </div>-->
    <!--  </div>-->
    <!--</div>-->

    <!--      </div>-->
    <!--    -->
    <!--          <div class="col-12 isotope-item js-id-optimal-control js-id-trajectory-planning">-->

    <!--<div class="col-lg-12 mb-5 view-showcase">-->
    <!--  <div class="row align-items-center">-->
    <!--    <div class="col-12 col-md-6">-->
    <!--      <div class="section-subheading article-title mb-0 mt-0"><a href="/research/construction_robot/" >Painting Robot in construction industry (RA Work)</a></div>-->
    <!--      -->
    <!--      <div class="article-style">-->
    <!--        A research topic focus on using mobile-based and 6 Dof manipulator to paint the indoor environment.-->
    <!--      </div>-->

    <!--      <div class="btn-links">-->
    <!--        -->

    <!--<a class="btn btn-outline-primary btn-page-header" href="https://www.researchgate.net/profile/Zhou-Yang-18/research" target="_blank" rel="noopener">-->
    <!--  PDF-->
    <!--</a>-->

    <!--  <a class="btn btn-outline-primary btn-page-header" href="https://www.zhihu.com/people/yuexiaozhu" target="_blank" rel="noopener">-->
    <!--    <i class="fab fa-zhihu mr-1"></i>Follow</a>-->

    <!--      </div>-->

    <!--    </div>-->
    <!--    <div class="col-12 col-md-6 order-first ">-->
    <!--      -->
    <!--        <a href="/research/construction_robot/" >-->
    <!--          <img src="/research/construction_robot/featured_hu75ea83f153be1e0c39c792f4b594fd5b_126483_540x0_resize_q75_h2_lanczos_3.webp" height="407" width="540"-->
    <!--              alt="Painting Robot in construction industry (RA Work)" loading="lazy">-->
    <!--        </a>-->
    <!--      -->
    <!--    </div>-->
    <!--  </div>-->
    <!--</div>-->

    <!--      </div>-->

    <!--  </div>-->
    <!--</div>-->
    <!--    -->
    <!--      </div>-->

    <!--    </div>-->
    <!--  </section>-->

    
          
          
<!--           -->

  <!--  <div class="page-footer">-->
  <!--    -->
  <!--    -->
  <!--    <div class="container">-->
  <!--      <footer class="site-footer">-->

  <!--  -->

  <!--  <p class="powered-by copyright-license-text">-->
  <!--    © 2022 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>-->
  <!--  </p>-->
  <!--  -->

  <!--  <p class="powered-by footer-license-icons">-->
  <!--    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">-->
  <!--      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>-->
  <!--      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>-->
  <!--      -->
  <!--        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>-->
  <!--      -->
  <!--      -->
  <!--        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>-->
  <!--      -->
  <!--    </a>-->
  <!--  </p>-->







  <!--  <p class="powered-by">-->
  <!--    -->
  <!--       -->
  <!--      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.-->
  <!--    -->
  <!--  </p>-->
  <!--</footer>-->

  <!--    </div>-->
  <!--    -->
  <!--  </div>-->


  <script src="/js/vendor-bundle.min.fab8b449b814cc9f95b22fcf2e45f05b.js"></script>

  <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js"
    integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw=="
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js"
    integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew=="
    crossorigin="anonymous"></script>
  

  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>

  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>

  <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js"
    integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw=="
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js"
    integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg=="
    crossorigin="anonymous"></script>



























  <script id="page-data" type="application/json">{"use_headroom":false}</script>
















  <script src="/en/js/wowchemy.min.0c1be879804fa6ae06a8f4c131cdbf54.js"></script>








  <div id="modal" class="modal fade" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <h5 class="modal-title">Cite</h5>
          <button type="button" class="close" data-dismiss="modal" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="modal-body">

          <pre><code></code></pre>
        </div>
        <div class="modal-footer">
          <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
            <i class="fas fa-copy"></i> Copy
          </a>
          <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
            <i class="fas fa-download"></i> Download
          </a>
          <div id="modal-error"></div>
        </div>
      </div>
    </div>
  </div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>


















</body>

</html>
